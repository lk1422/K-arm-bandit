# K-arm-bandit
K-arm-bandit implemented after completing first section of fundamentals of reinforcement learning:https://www.coursera.org/learn/fundamentals-of-reinforcement-learning/home/welcome


![image](https://user-images.githubusercontent.com/35120812/194971578-1eca6d36-a9c6-4862-8b69-d7fd1567c597.png)
The Example above uses optimistic initialization with a exploration rate of .1 , meaning 10% of the time
the agent selects a un-optimal solution in order to explore the other arms (options).

